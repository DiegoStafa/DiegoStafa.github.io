<!DOCTYPE html>

<html>

<head>
    <title>Diego++</title>

    <!-- meta data-->
    <meta charset="utf-8">
    <meta content="IE=edge" http-equiv="X-UA-Compatible">
    <meta content="width=device-width, initial-scale=1" name="viewport">

    <!-- css -->
    <link rel="stylesheet" href="/css/base.css">
    <link rel="stylesheet" href="/css/post.css">

    <!-- fonts & icons-->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Mono&display=swap">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>

<body>
    <div class="post-wrapper">
        <ul class="post-info">
            <li>
                Title:
            </li>
            <li>
                Author: Diego Stafa
            </li>
            <li>
                Date:
            </li>
        </ul>
        <div class="post"><h2>Ciclo d'esecuzione della CPU</h2>

<p>L'esecuzione di un istruzione nella cpu prevede 5 (o più) fasi diverse eseguite una alla volta:
1. fetch dell'istruzione (FI)
2. decode dell'istruzione (DE)
3. fetch degli operandi (FO)
4. esecuzione dell'istruzione (EX)
5. write in memoria per salvare il risultato (WM)</p>

<p>NB: Le fasi sopra scritte vengono eseguite da componenti hardware interni alla cpu, dedicati solo a quel preciso lavoro.</p>

<p>NB: ogni componente può gestire SOLO UNA istruzione ciò implica che durante ogni ciclo di clock non ci possono essere 2 istruzioni diverse nella stessa fase.</p>

<p>NB: il tempo di eseuzione di una fase è un di 1 ciclo di clock.</p>

<h3>Esecuzione di un programma senza pipeline</h3>

<p>Si fornisce alla cpu un istruzione e si attende fino al completamento della quinta fase prima di passare all'istruzione successiva.</p>

<h3>Idea di base della pipeline</h3>

<p>I componenti interni non sono vincolati l'un l'altro, quidi istruzioni diverse possono tranquillamente trovarsi in fasi diverse in uno stesso ciclo di clock</p>

<p>Di base quindi quando si esegue un'istruzione (aka quando il componente che si occupa dei fetch è libero) si fa il <b>prefetch</b> delle istruzioni successive.</p>

<p>NB: si usa prefetch per indicare l'atto di portare in cpu un istruzione prima che quella precedente sia terminata, mentre si usa fetch per indicare solo l'atto di portare un istruzione in cpu</p>

<h3>Confronto</h3>

<p>no pipeline &ndash;> la cpu gestisce un'istruzione per volta
* pro: semplice da implementare e funziona
* contro: tempo di esecuzione di un programma maggiore poichè spreca risorse</p>

<p>pipeline &ndash;> la cpu gestisce più istruzioni per volta e a regime massimo c'è un'istruzione per fase
* pro: componenti sfruttati al 100%
* contro: si possono presentare criticità (data hazards)</p>

<h2>Data hazards</h2>

<ul>
<li>sbilanciamento delle fasi &ndash;> bisogna assicurarsi che le fasi abbiano egual durata</li>
<li>problemi strutturali &ndash;> conflitti di accesso alla memoria</li>
<li>dipendenze dei dati &ndash;> bisogna mantenere la logica sequenziale di un programma</li>
<li>dipendenze di controllo &ndash;> jump e istruzioni che modificano il flusso del programma</li>
</ul>


<h3>sbilanciamento delle fasi</h3>

<p>Di base le fasi devono durare tutto lo stesso tempo, se infatti queste avessero durata diversa allora siccome ogni fase gestisce solo un'istruzione, si creerebbero ritardi, aka un istruzione in una fase precedente non può avanzare alla successiva perchè ancora occupata</p>

<p><b>soluzioni:</b>
1. ogni fase dura tanto quanto quella che dura di più
2. si cerca di decomporre al massimo la fase che dura di più
3. si introduce dell'hardware aggiuntivo per ridurre il tempo di esecuzione della fase più onerosa</p>

<h3>problemi strutturali</h3>

<p>Di base si riferiscono agli accessi in memoria tra diverse istruzioni, infatti le fasi FI, FO e WO, seppur indipendenti devono comunque accedere alla memoria per eseguire il loro lavoro, dalla definizione di pipeline, in ogni istante tutte le fasi sono occupate da diverse istruzioni, siccome bisogna mantenere la sequenzialita logica del programma, l'istruzione entrata per prima deve avere l'accesso.</p>

<p><b>soluzioni:</b>
1. si aggiunge il comando NOP per far attendere le altre fasi, di base nop non fa nulla, le istruzione rimangono nella loro fase in attesa che si liberi la memoria (soluzione poco efficente)
2. si suddivide la memoria in memoria dati e memoria istruzioni cosicchè entrambe le fasi possano accedervi contemporaneamente</p>

<h3>Dipendenze dei dati</h3>

<p>si verifica quando un istruzione successiva utilizza dei dati che l'istruzione precedente non ha ancora finito di manipolare (l'istruzione userebbe dati non aggiornati infatti)
ciò implica che un istruzione n dipende da quella n-1.</p>

<p>queste dipendenze si possono verificare in 3 forme diverse:</p>

<ul>
<li>read after write &ndash;> si fa una lettura di un dato prima che l'istruzione precedente abbia finito di modificarlo (aka si legge un dato non ancora aggiornato)</li>
<li>write after read &ndash;> si sovrascrive un dato prima che l'istruzione precedente l'abbia letto</li>
<li>write after write &ndash;> l'istruzione precedente sovrasvrive il dato di quella successiva, ciò non rispetta la sequenzialita logica di un programma, in memoria ci sarà il dato sbagliato</li>
</ul>


<p>NB: Quando si parla di dipendenze dei dati è implicito il fatto che l'istruzione N accede alla memoria prima dell'istruzione N-1.</p>

<p>il quarto caso:
* read after read &ndash;> non crea problemi (sono solo 2 letture, l'ordine non conta)</p>

<p><b>soluzioni:</b>
1. si aggiunge il comando NOP come prima (poco efficente)
2. si riordinano le istruzione in modo tale che ci si ritrovi nella forma read after read
3. si aggiunge hardaware aggiuntivo per implementare il data forwarding (aka le fasi si passano dati tra loro ed evitano write after write, read after write)</p>

<p>NB: il data forwarding di base consiste nel attaccare fisicamente con delle linee la fase di EX e la fase di FO e WM</p>

<h3>Dipendenze di controllo</h3>

<p>Ricordando che la pipeline fa il prefetch delle istruzioni in modo sequenziale (aka fa il prefetch di istruzioni successive), un istruzione di jump che porta l'esecuzione del programma in punto totalmente diverso implica che la pipeline dovrà scartare tutte le istruzioni di cui ha fatto il prefetch e caricare in cpu quelle a successive al target del jump.</p>

<p>NB: il target è l'indirizzo dell'istruzione a cui si vuole saltare.</p>

<p>per analizzare il problema si suddividono i tipi di jump in:
* salto incondizionato &ndash;> istruzione che salta al target in ogni caso
* salto condizionato &ndash;> istruzione che salta al target solo al rispettarsi di una condizione</p>

<h4>salto incondizionato</h4>

<p>la pipeline inizia a caricare le istruzione del target al completamento della fase di decode (qualche prefetch lo deve scartare in ogni caso).</p>

<p>non ha <b>soluzioni</b>.</p>

<h4>salto condizionato</h4>

<p>in questo caso la pipeline non può caricare il target durante il decode, poichè la veridicità della condizione la si può conoscere solo al termine della fase di EX.</p>

<p><b>soluzioni:</b>
* flussi multipli &ndash;> prefetch rami sia di verità che di falsità
* buffer circolare &ndash;> piccola memoria che si salva i prefetch precedenti
* predizione dei salti
  * statica &ndash;> carica sempre o il ramo vero o il ramo falso
  * dinamica &ndash;> carica un ramo in base a risultati precedenti
* salto ritardato &ndash;> fa il prefetch di istruzioni indipendenti</p>

<p>NB: queste soluzioni NON risolvono lo scarto dei prefetch, ma lo riducono.</p>

<h5>flussi multipli</h5>

<p>di base fa fetch e decode di entrambi i rami
pro: ha sicuramente quello giusto
contro: ha sicuramente quello sbagliato</p>

<h5>buffer circolare</h5>

<p>in pratica si aggiunge alla cpu un piccola memoria (qualche centinaia di byte) che si utilizza come cronologia dei prefetch, per ridurre al minimo il tempo sprecato.</p>

<p>si puo usare anche al contrario usandolo per salvare il prefetch delle istruzioni successive.</p>

<p>NB: per entrambi i casi vale il fatto che solitamente il target di una jump si trova a distanza di poche istruzioni che sia avanti o indietro</p>

<h4>predizione dei salti</h4>

<p><b>Statici:</b>
- ottimista &ndash;> carica sempre i rami veri
- pessimista &ndash;> carica sempre i rami falsi</p>

<p><b>Dinamici:</b>
di usano dei bit per ricordarsi cosa si è fatto nella jump precedente e si agisce di conseguenza.</p>

<ul>
<li>1 bit &ndash;> ricorda solo un salto, se salta setta il bit a 1, quando si ripresenta la jump allora la pipeline farà il prefetch del ramo di verita
se non salta la pipeline dovra scartare il prefetch e settare il bit a 0.</li>
<li>2 bit &ndash;> ricorda 2 salti</li>
</ul>


<h4>salto ritardato</h4>

<p>siccome la condizione la si conosce solo al termine della fase di EX, se si riempe la pipeline di istruzioni del programma indipendenti dal salto in modo tale che ad un certo punto la fase di EX verrà eseguita, allora non si dovrà scartare alcun prefetch e la cpu è stata comunque a regime massimo.
l'unico contro è che non è sempre applicabile.</p>

<p>NB: il riordino delle istruzioni viene fatto dal compilatore</p>

<h2>valutazione delle prestazioni</h2>
</div>
</div>
</body>

</html>