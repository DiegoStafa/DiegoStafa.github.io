**rappresentazione dei reali**

un reale è formato da:
* parte intera --> numero naturale
* parte frazionaria --> numero reale \[0,1\]

fissata una base b naturale, allora ogni reale è calcolato in uesto modo:
* parte intera --> j+++inf c*b<sup>j</sup>
* parte frazionaria --> j+++inf c*b<sup>-j</sup>

dove:
* c è la cifra
* b è la base fissata elevata alla sua posizione

**approssimazione dei reali**

il troncamento di un reale è dato da:
* parte intera --> j+++inf c*b<sup>j</sup>
* parte frazionaria --> j+++N c*b<sup>-j</sup>

l'arrotondamento di un reale è dato da:
* parte intera --> j+++inf c*b<sup>j</sup>
* parte frazionaria --> j+++N c*b<sup>-j</sup>
    * l'ultima cifra frazionaria è incrementata se la cifra successiva > b/2 e decrementata altrimenti

il troncamento aprossima un intorno destro
l'arrotondamento aprossima un intorno simmetrico

**errore assoluto**

dato un numero reale r ed una sua approssimazione a, l'errore assoluto dell'approssimazione è dato da:
* E  = \| r - a \|

l'errore di arrotondamento è al massimo grande uanto il raggio dell'intorno, l'errore su intorno destro è uguale all'errore del troncamento, ma l'errore su intorno sinistro p certamente minore

**virgola mobile**

di base è la notazione scientifica, ogni reale scritto in forma convenzionale, si può riscrivere come:
* 0.mantissa * b<sup>p</sup>

dove:
* mantissa --> parte intera e parte frazionaria
* p --> di uanto si è spostata la virgola

**reali macchina**

si utilizza un insieme finito di numeri razionali in virgola mobile per rappresentare i reali

**errore relativo**

dato un numero reale r ed una sua approssimazione a, l'errore relativo dell'approssimazione è dato da:
* E  = \| r - a \| / \|r\| --> si vede subito che è una percentuale

**precisione di macchina**

è il massimo errore relativo su reali macchina, dipende solo dal numero di bit a disposizione

è il più piccolo numero macchina positivo che sommato ad 1, viene arrotondato ad 1

data una mantissa m  ed una base b, la precisione di macchina è:
* b<sup>m - 1</sup> /2

**aritmetica macchina**

l'aritmetica macchina differisce da uella reale

un operazione è stabile se l'ordine di grandezza dell'errore sul risultato è al più uguale a uello sui dati

* radice
    * stabile
* prodotto
    * stabile, si dimostra aggiungendo e togliendo xy e usando disuguaglianza triangolare
* reciproco
    * è stabile
* divisione
    * stabile in uanto prodotto e reciproco stabili
* somma algebrica -->
    * stabile su segni concordi, si ha una combinazione lineare sui pesi w1,w2, dove w1=x/x+y e w2=y/x+y, uesti pesi sono sempre < 1
    * instabile su segni discordi (sottrazione) il denominatore può andare vicino a 0, aumentando infinitmaente l'ordine di grandezza dell'errore

i pesi delle combinazioni lineari sono i fattori di amplificazione dell'errore

dato un sistema floating point descritto in F(base, mantissa, L,U), l'esecuzione di un operazione è uesta:
* si arrotondano i dati su precisisione macchina
* si esegue l'operazione --> si calcola l'errore aritmetico
* si arrotonda il risultato su precisione macchina

**condizionamento delle funzioni**

l'errore su f(x) nel punto x, dove x è un numero macchina, euivale a condizionamento di f(x) che moltiplica l'errore di x

il condizionamento della funzione è:
* \|f'(x)\| * \|x\| / \|f(x)\| --> indice di condizionamento

questo indice può essere sia grande (instabilità) che piccolo (stabilità)

quindi di base se si vuole calcolare l'instabilità di una funzione si calcola il suo indice di condizionamento, poi per verficare se è stabile su un determinato xsi fa:
* lim x->x0 (cond(x)), se tende ad inf è instabile 

**algoritmo stabile**

è una algoritmo che gestisce bene la propagazione di tutti gli errori

**algoritmi iterativi di successioni**

se l'algoritmo è instabile una successioni convergente può anche divergere

**costo computazionale degli algoritmi numerici**

due parametri:
* flops (machine indipendent)
* tempo di calcolo (machine dependent)

i flops sono il numero di operazioni floating point

il tempo di calcolo è influenzato da:
* velocità del processore (petaflops/exaflops...)
* velocità di accesso alla memoria

es1:
* calcolo di un polinomio
* p(x) = a0 + a1x + ... + anx^n
* ha 3n flops (calcolato normalemente)
* se si raccolgono le x diventa a 2n flops
* ha uno speed-up di 3/2

es2:
* calcolo di potenza
* a^n
* ha n-1 flops (calcolato normalemente)
* si riscrive a^n = a^0 * a^1 ... a^2n, di base si riscrive l'esponente come somma di potenze di 2
* il numero di flops diventa 2log(n)
* speed up di n/2logn

calcolo dell'esponenziale rapido:
* si riscrive l'esponente e si approssima con taylor

**metodo di bisezione**

trova uno 0 di una funzione continua in un intervallo a-b, funzionamento:
* si trova il punto medio m di a-b (con f(a) e f(b) discordi)
* se f(m) è discorde con f(b) si riapplica su m-b
* se f(m) è discorde con f(a) si riapplica su a-m


stime:
* sottostima --> va evitata
* sovrastima --> può essere usata ma non è perfetta 